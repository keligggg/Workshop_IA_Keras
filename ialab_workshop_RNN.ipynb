{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ialab_workshop_RNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tntLvq7EZStJ"},"source":["## Introduction aux Réseaux de Neurones\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"jpnkFfqTZesH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f55b7c9d-25b8-4783-e2c4-9ffbfc9413ab"},"source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# Paramètres utiles pour le modèle\n","num_classes = 10\n","input_shape = (28, 28, 1)\n","\n","# données train et test sets\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","\n","# Normalisation (Les réseaux de neurones préfèrent des valeurs entre -1 et 1)\n","x_train = x_train.astype(\"float32\") / 255\n","x_test = x_test.astype(\"float32\") / 255\n","\n","# On s'assure que les images sont 3D (hauteur, largeur, profondeur) et non pas 2D (hauteur, largeur)\n","if len(x_train.shape) == 3:\n","  x_train = np.expand_dims(x_train, -1)\n","  x_test = np.expand_dims(x_test, -1)\n","\n","print(\"x_train shape:\", x_train.shape)\n","print(x_train.shape[0], \"train samples\")\n","print(x_test.shape[0], \"test samples\")\n","\n","\n","# Conversion des labels par exemple 2 en [0, 0, 1, 0, 0, 0] (mais ici on est sur des vecteurs de dimension 10)\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wnyVBBfOrQyI"},"source":["## Réseau de Neurones Artificiel (ANN ou FNN)"]},{"cell_type":"code","metadata":{"id":"NEk2g-IFb7Dw","colab":{"base_uri":"https://localhost:8080/","height":369},"outputId":"c35b08ab-2918-4867-8baa-80a1c5d5bd97"},"source":["# Créer ton modèle !\n","\n","from tensorflow.keras import Input\n","from tensorflow.keras.layers import Flatten, Dense, Dropout\n","\n","# Vous aurez besoin d'utiliser ces layers :                  (Ici les arguments nécessaires pour programmer les layers)\n","#                                           - Input        # shape\n","#                                           - Flatten\n","#                                           - Dense        # units, activation\n","#                                           - Dropout      # rate\n","\n","# Les variables à ta disposition sont : \n","#                                       - input_shape \n","#                                       - num_classes \n","\n","######################## Ton code ici ##############################\n","\n","model = keras.Sequential(\n","    [\n","        Flatten(input_shape=input_shape),\n","        Dense(512, activation=\"relu\"),\n","        Dropout(0.4),\n","        Dense(512, activation=\"relu\"),\n","        Dropout(0.4),\n","        Dense(10, activation=\"softmax\")\n","    ]\n",")\n","\n","######################## Ton code ici ##############################\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_1 (Flatten)          (None, 784)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               401920    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 669,706\n","Trainable params: 669,706\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZSv-KOyZb_Cf","colab":{"base_uri":"https://localhost:8080/","height":213},"outputId":"c0f0414d-021b-4196-dc1e-7e54f479b83e"},"source":["# Training\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","batch_size = 128   # Le nombre d'exemples que l'IA va voir d'un coup\n","epochs = 5         # Le nombre de fois que l'IA va voir l'ensemble des données\n","\n","model.compile(loss=\"categorical_crossentropy\",     # Fonction d'erreur\n","              optimizer=Adam(learning_rate=0.001), # Optimisation de l'apprentissage\n","              metrics=[\"accuracy\"])                # Mesure de la précision\n","\n","model.fit(x_train,               # Images\n","          y_train,               # Labels\n","          batch_size=batch_size, # Le nombre d'exemples que l'IA va voir d'un coup\n","          epochs=epochs,         # Le nombre de fois que l'IA va voir l'ensemble des données\n","          validation_split=0.1);  # Le pourcentage d'exemples de vérification (sur lesquels l'IA ne s'entraînera pas)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","422/422 [==============================] - 2s 5ms/step - loss: 0.3239 - accuracy: 0.9008 - val_loss: 0.1039 - val_accuracy: 0.9700\n","Epoch 2/5\n","422/422 [==============================] - 2s 5ms/step - loss: 0.1403 - accuracy: 0.9571 - val_loss: 0.0805 - val_accuracy: 0.9782\n","Epoch 3/5\n","422/422 [==============================] - 2s 5ms/step - loss: 0.1075 - accuracy: 0.9666 - val_loss: 0.0738 - val_accuracy: 0.9785\n","Epoch 4/5\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0895 - accuracy: 0.9721 - val_loss: 0.0690 - val_accuracy: 0.9783\n","Epoch 5/5\n","422/422 [==============================] - 2s 5ms/step - loss: 0.0751 - accuracy: 0.9761 - val_loss: 0.0654 - val_accuracy: 0.9807\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pH9fHBFfcNpn","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"c4e4b0d7-9608-4bfc-9f4f-03c4e32c64eb"},"source":["# Evaluate\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss: 0.06610465049743652\n","Test accuracy: 0.9799000024795532\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9VecaDMs9yrr","colab":{"base_uri":"https://localhost:8080/","height":301},"outputId":"458ba12e-ed66-496a-dfa1-dc39ed553cf0"},"source":["# Teste ton modèle sur une image en particulier !\n","\n","from random import randint\n","\n","indice = randint(0, y_test.shape[0]-1)\n","\n","image = x_test[indice]\n","label = np.argmax(y_test[indice])\n","\n","image = np.expand_dims(image, 0) # permet d'avoir un batch_size = 1\n","#                                # car l'IA prend des données de dimension 4 (batch_size, hauteur, largeur, channels)\n","#                                # channels sert pour les images en couleurs par exemple (RGB)\n","\n","prediction = model.predict(image)   # On effectue la prédiction\n","\n","prediction = np.squeeze(prediction) # On enlève les dimensions inutiles (ici batch_size : en effet on passe d'une matrice (1, 10) à un vecteur (10,))\n","\n","prediction = np.argmax(prediction)  # Changer [0, 0, 1, 0, 0, 0] en 2 par exemple (mais ici on est sur des vecteurs de dimension 10)\n","\n","import matplotlib.pyplot as plt\n","\n","print(\"\\n Voici un\", label, \"et l'IA a vu un\", prediction, \"... \\n\")\n","\n","plt.axis('off')\n","plt.imshow(np.squeeze(image), cmap=plt.get_cmap(\"gray\"));"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," Voici un 9 et l'IA a vu un 9 ... \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAHYklEQVR4nO3dQWjX9R/H8d9PTCc1RVCIwaI6rEuQ5kEkj5KKXTx0CYMEF4RD9OBBvO0QMnfKiNCCSC8TwaB2mkWHgjrUoUOKVCwSdpohIqJEv//tf/nv+/66Tf97bXs8jr34zq/asy/04fv7dXu9XgfIs2apbwCYmzghlDghlDghlDgh1Npq7Ha7/lcuPGG9Xq871z/35IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQa5f6Blai9evXl/vhw4cbt5MnT5bXvvDCCwu6p0c1NjbWuH388cfltdPT04/5blY3T04IJU4IJU4IJU4IJU4IJU4I1e31es1jt9s8rmIDAwPl/sknn5T73r17G7dut1te+91335X7P//8U+6vvvpquW/cuLFxu3v3bnnt0aNHy/3SpUvlvlr1er05/9I9OSGUOCGUOCGUOCGUOCGUOCGUOCGUV8YWoDqnfJS98umnn5b7e++9V+5t55wvvvhiuT/zzDON25EjR8prR0ZGyv3rr78u99u3bzduw8PD5bV9fX3lfuXKlXJPfN3NkxNCiRNCiRNCiRNCiRNCiRNCiRNCeZ9zDm+++Wa5f/755+W+bt26cj9//nzjNjo6Wl47MzNT7snazlgvX77cuG3fvn1Rv/a+ffvKfWpqalE/fzG8zwnLjDghlDghlDghlDghlDghlDgh1Kp8n3P37t3lPjExsaif/+GHH5b7sWPHFvXzU+3fv7/cJycny736zN7qPH6l8uSEUOKEUOKEUOKEUOKEUOKEUOKEUCv2nHNoaKhx+/LLLxf1s48fP17uH3300aJ+/lLq7+9v3No+t/bMmTPlXn0ubafT6bzxxhuN2xdffFFeu3Xr1nJfjjw5IZQ4IZQ4IZQ4IZQ4IZQ4IdSyPUp56qmnyv306dON28aNG8tr2175ajsqafsavqW0YcOGch8fH2/c2o5SZmdny706Kul0Op01a5qfFZs3by6vvXXrVrn/8MMP5Z7IkxNCiRNCiRNCiRNCiRNCiRNCiRNCLdtzzgMHDpT7oUOHGrc//vijvHY5f3Rl2znm1atXy/31119v3H7//ffy2ra/k5s3b5Z79crZ2rX1v6rvvvtuud+9e7fcE3lyQihxQihxQihxQihxQihxQihxQqhu9dVq3W53yb537eWXXy73H3/8sdyrdwNfe+218tqff/653JfSzp07y73tXdQdO3aU+9TUVON24sSJ8tpff/213Nv8+++/C75227Zt5f7LL78s+Gc/ab1eb87vPvTkhFDihFDihFDihFDihFDihFDihFCx73MODAyUe19fX7nfuHGjcUs+xxwdHS33trPGe/fulfvRo0fL/bPPPmvc7t+/X17bZs+ePQu+tu1rGxd7xprIkxNCiRNCiRNCiRNCiRNCiRNCiRNCxZ5ztn0GapuvvvrqMd3J/D399NPl/sEHHzRuhw8fLq/9888/y31kZKTcJycny30x2n7f586dW/DPbvtc2uTvRF0oT04IJU4IJU4IJU4IJU4IJU4IFXuUstjXur755pvHdCf/6/333y/3gwcPlvvQ0FDj9v3335fXDg8Pl3v1qtyT1t/fX+7V77vT6XR++umnxu3vv/9e0D0tZ56cEEqcEEqcEEqcEEqcEEqcEEqcECr2nHNmZqbcu905vzXtv8bHxxu3t956q7z27bffLvc2Dx48KPdTp041bmNjY4v6tZ+ktnPMixcvlnvb31n15/Lw4cPy2pXIkxNCiRNCiRNCiRNCiRNCiRNCiRNCdXu9XvPY7TaPT9jzzz9f7t9++225Dw4OLvjX/uuvv8r9woUL5T4xMVHuv/3227zvKcErr7xS7m3v4La9k7lly5Z539NK0Ov15jwA9uSEUOKEUOKEUOKEUOKEUOKEUOKEULHvc05PT5f7rl27yv2dd95p3NrO29rOKVfjZ6g+DmfPnl3qW1hWPDkhlDghlDghlDghlDghlDghVOwrY+Q5ceJEuZ8+fbrcX3rppXKfnZ2d9z2tBF4Zg2VGnBBKnBBKnBBKnBBKnBBKnBDKOSePrO2jL5999tlyHxgYeJy3s2I454RlRpwQSpwQSpwQSpwQSpwQSpwQKvajMclz7dq1cj906ND/6U5WB09OCCVOCCVOCCVOCCVOCCVOCCVOCOWck0d2/fr1cl+zpv5v/aZNm8r9zp07876nlcyTE0KJE0KJE0KJE0KJE0KJE0KJE0L53Foe2XPPPVfubZ9re//+/XIfHByc9z2tBD63FpYZcUIocUIocUIocUIocUIoRymwxBylwDIjTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTghVvs8JLB1PTgglTgglTgglTgglTgglTgj1H08iXlA2MbOJAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"FRSgXE4jrd8B"},"source":["## Réseau de Neurones à Convolutions (CNN)"]},{"cell_type":"code","metadata":{"id":"8Z-RheyWq4cj","colab":{"base_uri":"https://localhost:8080/","height":386},"outputId":"7a50d0bd-2eb4-45a6-c9bd-2865e7eff94b"},"source":["# Créer ton modèle !\n","\n","from tensorflow.keras import Input\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n","\n","# Vous aurez besoin d'utiliser ces layers :                # (Ici les arguments nécessaires pour programmer les layers)\n","\n","#                                           - Conv2D       # filters, kernel_size, activation, input_shape\n","#                                           - MaxPooling2D # pool_size\n","#                                           - Flatten\n","#                                           - Dropout      # rate\n","#                                           - Dense        # units, activation (comme pour Conv2D)\n","\n","# Les variables à ta disposition sont : \n","#                                       - input_shape \n","#                                       - num_classes \n","\n","######################## Ton code ici ##############################\n","\n","model = keras.Sequential(\n","    [\n","        Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=input_shape),\n","        MaxPooling2D(pool_size=2),\n","        Conv2D(64, kernel_size=3, activation=\"relu\"),\n","        MaxPooling2D(pool_size=2),\n","        Flatten(),\n","        Dropout(0.5),\n","        Dense(num_classes, activation=\"softmax\"),\n","    ]\n",")\n","\n","######################## Ton code ici ##############################\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1600)              0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1600)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                16010     \n","=================================================================\n","Total params: 34,826\n","Trainable params: 34,826\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"94YcItVLq1ET","colab":{"base_uri":"https://localhost:8080/","height":185},"outputId":"dbc352c2-583f-4003-f52c-65cd7d0dd865"},"source":["# Training\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","batch_size = 128   # Le nombre d'exemples que l'IA va voir d'un coup\n","epochs = 5         # Le nombre de fois que l'IA va voir l'ensemble des données\n","\n","model.compile(loss=\"categorical_crossentropy\",     # Fonction d'erreur\n","              optimizer=Adam(learning_rate=0.001), # Optimisation de l'apprentissage\n","              metrics=[\"accuracy\"])                # Mesure de la précision\n","\n","model.fit(x_train,                # Images\n","          y_train,                # Labels\n","          batch_size=batch_size,  # Le nombre d'exemples que l'IA va voir d'un coup\n","          epochs=epochs,          # Le nombre de fois que l'IA va voir l'ensemble des données\n","          validation_split=0.1);  # Le pourcentage d'exemples de vérification (sur lesquels l'IA ne s'entraînera pas)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","422/422 [==============================] - 4s 9ms/step - loss: 0.3667 - accuracy: 0.8875 - val_loss: 0.0755 - val_accuracy: 0.9807\n","Epoch 2/5\n","422/422 [==============================] - 3s 8ms/step - loss: 0.1127 - accuracy: 0.9655 - val_loss: 0.0583 - val_accuracy: 0.9830\n","Epoch 3/5\n","422/422 [==============================] - 3s 8ms/step - loss: 0.0838 - accuracy: 0.9733 - val_loss: 0.0450 - val_accuracy: 0.9870\n","Epoch 4/5\n","422/422 [==============================] - 3s 8ms/step - loss: 0.0702 - accuracy: 0.9779 - val_loss: 0.0403 - val_accuracy: 0.9890\n","Epoch 5/5\n","422/422 [==============================] - 3s 8ms/step - loss: 0.0610 - accuracy: 0.9808 - val_loss: 0.0366 - val_accuracy: 0.9897\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lVLVkdqhqyjO","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"f1010a77-e791-4351-fb19-6c795a4d7e00"},"source":["# Evaluate\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test loss: 0.03677176684141159\n","Test accuracy: 0.9876999855041504\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g4TUmQNJCbgH","colab":{"base_uri":"https://localhost:8080/","height":298},"outputId":"55134508-ab97-46e2-c5f3-9080ec2a9a3b"},"source":["# Teste ton modèle sur une image en particulier !\n","\n","from random import randint\n","\n","indice = randint(0, y_test.shape[0]-1)\n","\n","image = x_test[indice]\n","label = np.argmax(y_test[indice])\n","\n","image = np.expand_dims(image, 0) # permet d'avoir un batch_size = 1\n","#                                # car l'IA prend des données de dimension 4 (batch_size, hauteur, largeur, channels)\n","#                                # channels sert pour les images en couleurs par exemple (RGB)\n","\n","prediction = model.predict(image)   # On effectue la prédiction\n","\n","prediction = np.squeeze(prediction) # On enlève les dimensions inutiles (ici batch_size : en effet on passe d'une matrice (1, 10) à un vecteur (10,))\n","\n","prediction = np.argmax(prediction)  # Changer [0, 0, 1, 0, 0, 0] en 2 par exemple (mais ici on est sur des vecteurs de dimension 10)\n","\n","import matplotlib.pyplot as plt\n","\n","print(\"\\n Voici un\", label, \"et l'IA a vu un\", prediction, \"... \\n\")\n","\n","plt.axis('off')\n","plt.imshow(np.squeeze(image), cmap=plt.get_cmap(\"gray\"));"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," Voici un 1 et l'IA a vu un 1 ... \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAEhUlEQVR4nO3cvWpUWxiA4bNVLKwCKogRG0VsvAFTaKG3oIV4Aba5HCsb70As0sUyTTpB8B5SRG382aexETLraEZn3jk+Tzkfe7KaNx9ksTPN8/wP0HNm3QcATiZOiBInRIkTosQJUedGw2ma/CkX/rB5nqeTPrc5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR59Z9gL/RgwcPFs729vaGz07TNJw/f/58OH/27Nlw/u3bt+Gc1bE5IUqcECVOiBInRIkTosQJUeKEqGme58XDaVo85NQuXLiwcPbu3bvhs9vb20v97Pv37w/nb968Wer7+XXzPJ94eW1zQpQ4IUqcECVOiBInRIkTorwytgafPn1aODs8PBw++/Hjx+H81q1bw/nOzs5w7iqlw+aEKHFClDghSpwQJU6IEidEiROivDIWc+/eveH88ePHw/mTJ0+G8zNnxr+Pr169unB2fHw8fJbT8coYbBhxQpQ4IUqcECVOiBInRIkTorzPGbO/vz+cX79+fTh/+PDhcH7jxo3h/OzZs8M5q2NzQpQ4IUqcECVOiBInRIkTosQJUd7n/J95+/btcH779u3h/OnTpwtnL1++PNWZGPM+J2wYcUKUOCFKnBAlTogSJ0SJE6K8z8kPzp8/v+4j8J3NCVHihChxQpQ4IUqcECVOiHKVwg8+f/687iPwnc0JUeKEKHFClDghSpwQJU6IEidEuefkB69evVr3EfjO5oQocUKUOCFKnBAlTogSJ0SJE6Lcc26YS5cuDecXL15c0Un402xOiBInRIkTosQJUeKEKHFClDghyj3nhtnd3R3OL1++vKKT8KfZnBAlTogSJ0SJE6LECVHihChxQpR7zg1zfHy81PNHR0fD+ZcvX5b6fn4fmxOixAlR4oQocUKUOCFKnBDlKuUv8/r16+H8w4cPKzoJ/8XmhChxQpQ4IUqcECVOiBInRIkTotxz/mUODg7WfQR+ks0JUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0R5n3PD3Lx5c91HYEVsTogSJ0SJE6LECVHihChxQpSrlA1z586ddR+BFbE5IUqcECVOiBInRIkTosQJUeKEKPecMVtbW8P5tWvXlvr+vb29pZ5ndWxOiBInRIkTosQJUeKEKHFClDghyj1nzKNHj4bzK1euDOcvXrwYzt+/f/+rR2JNbE6IEidEiROixAlR4oQocUKUOCHKPWfM3bt3l3p+f39/OP/69etS38/q2JwQJU6IEidEiROixAlR4oQocULUNM/z4uE0LR4Cv8U8z9NJn9ucECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihKjhv8YE1sfmhChxQpQ4IUqcECVOiBInRP0L33d4uGo8c/wAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"d1qBFn0E8khC"},"source":["## Réseau de Neurones Récurrents (RNN)"]},{"cell_type":"code","metadata":{"id":"5GVOIjXM88cK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605634412542,"user_tz":-60,"elapsed":6607,"user":{"displayName":"Kelig Lefeuvre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjgo5FNeZxfzF-BbdJG9PY4CAkrAeZb3ALwyJbOaXo=s64","userId":"10344641853182449718"}},"outputId":"5c1bc909-ee04-4d49-f8e7-b20fbb503568"},"source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","max_nb_of_words = 20000    # On ne prend en compte que les _ 1ers mots\n","max_len = 200              # On ne regarde que les _ 1ers mots de chaque review\n","\n","(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_nb_of_words)\n","\n","word_to_int = keras.datasets.imdb.get_word_index()\n","int_to_word = dict()\n","\n","int_to_word[0] = \"<UNK>\"\n","for word, integ in word_to_int.items():\n","  int_to_word[integ] = word\n","\n","print(\"Longueur de chaque dict :\", len(word_to_int), len(int_to_word))\n","\n","print(len(x_train), \"Training sequences\")\n","print(len(x_test), \"Validation sequences\")\n","\n","x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)    # On formate chaque review pour qu'elles soient toutes de même longueur\n","x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)      # Même idée"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Longueur de chaque dict : 88584 88585\n","25000 Training sequences\n","25000 Validation sequences\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"73iYoPzXpgdc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605637535686,"user_tz":-60,"elapsed":920,"user":{"displayName":"Kelig Lefeuvre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjgo5FNeZxfzF-BbdJG9PY4CAkrAeZb3ALwyJbOaXo=s64","userId":"10344641853182449718"}},"outputId":"d542aeba-d1e5-4755-dcd7-420038a8ff4a"},"source":["# Créer ton modèle !\n","\n","from tensorflow.keras import Input, Model\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","# Vous aurez besoin d'utiliser ces layers :                # (Ici les arguments nécessaires pour programmer les layers)\n","#                                           - Input        # shape, dtype=\"int32\"\n","#                                           - Embedding    # input_dim, output_dim, (max_nb_of_words peut parfois être utile)\n","#                                           - LSTM         # units, return_sequences\n","#                                           - Dense        # units, activation (comme pour Conv2D)\n","\n","# Les variables à ta disposition sont : \n","#                                       - max_nb_of_words \n","#                                       - max_len \n","\n","######################## Ton code ici ##############################\n","\n","# Input for variable-length sequences of integers\n","inputs = Input(shape=(None,),dtype=\"int32\")\n","# Embedding qui associe à chaque entier un vecteur de dimension \"output_dim\"\n","x = Embedding(max_nb_of_words,128)(inputs)\n","\n","# Ajouter le ou les LSTM\n","x = LSTM(64,return_sequences=True)(x)\n","x = LSTM(64)(x)\n","x = Dense(64,activation=\"relu\")(x)\n","\n","\n","# Add a classifier\n","outputs = Dense(1, activation=\"sigmoid\")(x)\n","\n","######################## Ton code ici ##############################\n","\n","model = Model(inputs, outputs)\n","\n","model.summary()"],"execution_count":63,"outputs":[{"output_type":"stream","text":["Model: \"functional_30\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_24 (InputLayer)        [(None, None)]            0         \n","_________________________________________________________________\n","embedding_23 (Embedding)     (None, None, 128)         2560000   \n","_________________________________________________________________\n","lstm_40 (LSTM)               (None, None, 64)          49408     \n","_________________________________________________________________\n","lstm_41 (LSTM)               (None, 64)                33024     \n","_________________________________________________________________\n","dense_28 (Dense)             (None, 64)                4160      \n","_________________________________________________________________\n","dense_29 (Dense)             (None, 1)                 65        \n","=================================================================\n","Total params: 2,646,657\n","Trainable params: 2,646,657\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7WbFAU4spkPm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605637932591,"user_tz":-60,"elapsed":64836,"user":{"displayName":"Kelig Lefeuvre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjgo5FNeZxfzF-BbdJG9PY4CAkrAeZb3ALwyJbOaXo=s64","userId":"10344641853182449718"}},"outputId":"b4d9af3c-e8ae-42c3-cea9-59f275b9b249"},"source":["# Training\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","batch_size = 32    # Le nombre d'exemples que l'IA va voir d'un coup\n","epochs = 2       # Le nombre de fois que l'IA va voir l'ensemble des données\n","\n","model.compile(loss=\"binary_crossentropy\",          # Fonction d'erreur\n","              optimizer=Adam(learning_rate=0.001), # Optimisation de l'apprentissage\n","              metrics=[\"accuracy\"])                # Mesure de la précision\n","\n","model.fit(x_train,                # Images\n","          y_train,                # Labels\n","          batch_size=batch_size,  # Le nombre d'exemples que l'IA va voir d'un coup\n","          epochs=epochs,          # Le nombre de fois que l'IA va voir l'ensemble des données\n","          validation_split=0.1);  # Le pourcentage d'exemples de vérification (sur lesquels l'IA ne s'entraînera pas)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","704/704 [==============================] - 31s 45ms/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 0.6483 - val_accuracy: 0.8420\n","Epoch 2/2\n","704/704 [==============================] - 30s 43ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.6480 - val_accuracy: 0.8560\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MPu1TconpquP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605637947027,"user_tz":-60,"elapsed":8741,"user":{"displayName":"Kelig Lefeuvre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjgo5FNeZxfzF-BbdJG9PY4CAkrAeZb3ALwyJbOaXo=s64","userId":"10344641853182449718"}},"outputId":"66145a7e-4e85-4459-f6d5-a79f8a58decf"},"source":["# Evaluate\n","\n","score = model.evaluate(x_test, y_test, verbose=1)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"],"execution_count":68,"outputs":[{"output_type":"stream","text":["782/782 [==============================] - 7s 10ms/step - loss: 0.6873 - accuracy: 0.8458\n","Test loss: 0.6873285174369812\n","Test accuracy: 0.84579998254776\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2I-OnWGzwyjy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605637509155,"user_tz":-60,"elapsed":1204,"user":{"displayName":"Kelig Lefeuvre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjgo5FNeZxfzF-BbdJG9PY4CAkrAeZb3ALwyJbOaXo=s64","userId":"10344641853182449718"}},"outputId":"c12e937b-8815-499d-b723-154dda2e15a1"},"source":["# Teste ton modèle sur une review en particulier !\n","\n","from random import randint\n","\n","indice = randint(0, y_test.shape[0]-1)\n","\n","review = x_test[indice]\n","label = y_test[indice]\n","\n","review = np.expand_dims(review, 0)   # permet d'avoir un batch_size = 1 (même idée qu'avant)\n","\n","prediction = model.predict(review)   # On effectue la prédiction\n","\n","prediction = np.squeeze(prediction)  # On enlève les dimensions inutiles (ici batch_size : en effet on passe d'une matrice (1, 1) à un vecteur (1,))\n","\n","\n","review = [int_to_word[i] for i in review[0, :]] # Liste d'entiers -> liste de mots\n","\n","sequence = 20\n","print(\"\")\n","for i in range(0, len(review), sequence):\n","  print(' '.join(review[i:i+sequence]))\n","print(\"\")\n","\n","print(\"Cette review est\", \"positive.\" if label==1 else \"negative.\")\n","print(\"L'IA pense que cette review est\", \"positive.\" if prediction==1 else \"negative.\")"],"execution_count":62,"outputs":[{"output_type":"stream","text":["\n","<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> the as on\n","it of its romantic to makes on always life this is time both my movie is allen's and to is\n","completely chamberlain was although that in at ruined especially like and length memoir there that enjoy cohen nina it his\n","had so horrible was does not would it definitely of script down it definitely but were god expert enters me\n","we this spouse was rather doesn't that watch leaves cunningham america's her of moss br about with which up played\n","that it they gets below romantic was rather his had is completely br of roles br making this of you\n","not have also door this in of reading to same have he basic of 7 but they're as on fairly\n","in at up relatives dies comes asks scenes crowd gunned to is caught to be awesomely character that to can\n","\n","Cette review est positive.\n","L'IA pense que cette review est negative.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DkhWu9le9rXV"},"source":["## Réseau de Neurones Récurrents Bidirectionnels (BRNN)"]},{"cell_type":"code","metadata":{"id":"7ZQa3Eki949I","colab":{"base_uri":"https://localhost:8080/","height":319},"outputId":"c090b837-a7a2-4bf2-e5c4-ce1b3f1bd8a5"},"source":["# Créer ton modèle !\n","\n","from tensorflow.keras import Input, Model\n","from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n","\n","# Vous aurez besoin d'utiliser ces layers :                 # (Ici les arguments nécessaires pour programmer les layers)\n","#                                           - Input         # shape, dtype=\"int32\"\n","#                                           - Embedding     # input_dim, output_dim, (max_nb_of_words peut parfois être utile)\n","#                                           - Bidirectional\n","#                                           - LSTM          # units, return_sequences\n","#                                           - Dense         # units, activation (comme pour Conv2D)\n","\n","# Les variables à ta disposition sont : \n","#                                       - max_nb_of_words \n","#                                       - max_len \n","\n","######################## Ton code ici ##############################\n","\n","# Input for variable-length sequences of integers\n","inputs = \n","\n","# Embedding qui associe à chaque entier un vecteur de dimension \"output_dim\"\n","x = \n","\n","# Ajouter le ou les LSTM\n","x = #ajouter bidirectionnel en parametre bidirectional(LSTM(64,return_sequences=True)(x))\n","x = \n","\n","# Ajouter la sortie\n","outputs = \n","\n","######################## Ton code ici ##############################\n","\n","model = Model(inputs, outputs)\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, None)]            0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, None, 128)         2560000   \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, None, 128)         98816     \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 128)               98816     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 2,757,761\n","Trainable params: 2,757,761\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yC_ZL_-c99qK","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"7bc01875-453b-4e11-f8e4-7b6b4afea52f"},"source":["# Training\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","batch_size = 32    # Le nombre d'exemples que l'IA va voir d'un coup\n","epochs = 2         # Le nombre de fois que l'IA va voir l'ensemble des données\n","\n","model.compile(loss=\"binary_crossentropy\",          # Fonction d'erreur\n","              optimizer=Adam(learning_rate=0.001), # Optimisation de l'apprentissage\n","              metrics=[\"accuracy\"])                # Mesure de la précision\n","\n","model.fit(x_train,                # Images\n","          y_train,                # Labels\n","          batch_size=batch_size,  # Le nombre d'exemples que l'IA va voir d'un coup\n","          epochs=epochs,          # Le nombre de fois que l'IA va voir l'ensemble des données\n","          validation_split=0.1);  # Le pourcentage d'exemples de vérification (sur lesquels l'IA ne s'entraînera pas)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","704/704 [==============================] - 132s 188ms/step - loss: 0.4175 - accuracy: 0.8082 - val_loss: 0.3485 - val_accuracy: 0.8660\n","Epoch 2/2\n","704/704 [==============================] - 131s 186ms/step - loss: 0.2174 - accuracy: 0.9164 - val_loss: 0.3569 - val_accuracy: 0.8568\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K11JuvWe-Bu9","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"6727ae9b-6d73-4cd3-84b9-3f91cd7fb97b"},"source":["# Evaluate\n","\n","score = model.evaluate(x_test, y_test, verbose=1)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["782/782 [==============================] - 56s 71ms/step - loss: 0.3589 - accuracy: 0.8572\n","Test loss: 0.358852744102478\n","Test accuracy: 0.857200026512146\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vaMPh-x1-Eaq","colab":{"base_uri":"https://localhost:8080/","height":252},"outputId":"b5870039-05d5-4162-b0cc-de6f3fd05323"},"source":["# Teste ton modèle sur une review en particulier !\n","\n","from random import randint\n","\n","indice = randint(0, y_test.shape[0]-1)\n","\n","review = x_test[indice]\n","label = y_test[indice]\n","\n","review = np.expand_dims(review, 0)   # permet d'avoir un batch_size = 1 (même idée qu'avant)\n","\n","prediction = model.predict(review)   # On effectue la prédiction\n","\n","prediction = np.squeeze(prediction)  # On enlève les dimensions inutiles (ici batch_size : en effet on passe d'une matrice (1, 1) à un vecteur (1,))\n","\n","\n","review = [int_to_word[i] for i in review[0, :]] # Liste d'entiers -> liste de mots\n","\n","sequence = 20\n","print(\"\")\n","for i in range(0, len(review), sequence):\n","  print(' '.join(review[i:i+sequence]))\n","print(\"\")\n","\n","print(\"Cette review est\", \"positive.\" if label==1 else \"negative.\")\n","print(\"L'IA pense que cette review est\", \"positive.\" if prediction==1 else \"negative.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> the then stupid\n","we as you with makes it's is over makes that with is group ship to by br of sure characters\n","always your life influential lovely it see makes are journey and influential lovely ever watch doesn't be probably an was\n","well why it all it his way but characters film is alain guy it's up just even using music director\n","in perfect have killers truly br sad victor arts as on it is group bought an of too they of\n","here br of you influential lovely lines is harsh all borrowed what have asked as you stupid great that with\n","very his which of harsh after looked of on all away comic make painfully at is fond was story br\n","dead as is breaking didn't not of elm sex it later loved then which hope man my are as judge\n","\n","Cette review est negative.\n","L'IA pense que cette review est negative.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"btpwRyO99u-n"},"source":[""],"execution_count":null,"outputs":[]}]}